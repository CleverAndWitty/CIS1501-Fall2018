{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LetterCount",
      "provenance": [],
      "authorship_tag": "ABX9TyPACtpWzP+xRIpLa3yUvHNc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CleverAndWitty/CIS1501-Fall2018/blob/master/LetterCount.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "-bwphMHC4lcD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8bfd99e-d054-4ab2-d7ce-2499745799ff"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 32 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 48.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=d5a687ca449887d3ed5927050061f12384b1a4e82811dbc0e5754b2f7adc8dfd\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "import re #Regular Expressions\n",
        "\n",
        "conf = SparkConf().setAppName('SparkWordCount')\n",
        "sc = SparkContext.getOrCreate(conf = conf)\n",
        "\n",
        "sqlContext = SparkSession.builder\\\n",
        "    .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "            .config('spark.ui.port', '4050')\\\n",
        "                .getOrCreate()\n",
        "        "
      ],
      "metadata": {
        "id": "zmCPBwbE4foD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Input File"
      ],
      "metadata": {
        "id": "2rXGnzubGLKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_file = sc.textFile('Sample.txt')"
      ],
      "metadata": {
        "id": "hUnLwbVsEnQv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to return each letter in a string"
      ],
      "metadata": {
        "id": "U8KxsgrpZRsG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alphabet = r\"[a-zA-Z]\"\n",
        "\n",
        "def LettersInWord(StringInput):\n",
        "  for i in range(len(StringInput)):\n",
        "    if re.match(alphabet, StringInput[i]):\n",
        "      return StringInput[i].lower()"
      ],
      "metadata": {
        "id": "7V3aEeHKZRde"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Map by characters"
      ],
      "metadata": {
        "id": "92gMOcO_GFr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Words = input_file.flatMap(\n",
        "    lambda line: line.split())\n",
        "Letters = Words.map(lambda word : LettersInWord(word), Words)\n",
        "LetterCount = Letters.map(lambda letter : (letter , 1))\n",
        "countKeys = LetterCount.reduceByKey(lambda a, b : a + b)"
      ],
      "metadata": {
        "id": "IBvvJT1MS4Uy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "da0c403f-c7b2-40df-d925-42c0c3bf6e5a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-85fd9f730833>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m Words = input_file.flatMap(\n\u001b[1;32m      2\u001b[0m     lambda line: line.split())\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mLetters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mword\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mLettersInWord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphabet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mLetterCount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLetters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mletter\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mletter\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcountKeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLetterCount\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduceByKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'PipelinedRDD' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the DataFrame and display it"
      ],
      "metadata": {
        "id": "ytkoZnukaiwW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hk_mU04W4VBd",
        "outputId": "34f6d5bb-86a4-4c73-cdea-b9d9557d3873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+\n",
            "|Letter| Count|\n",
            "+------+------+\n",
            "|     a| 85667|\n",
            "|     b| 45597|\n",
            "|     c| 34694|\n",
            "|     d| 29830|\n",
            "|     e| 19116|\n",
            "|     f| 36930|\n",
            "|     g| 21021|\n",
            "|     h| 60736|\n",
            "|     i| 62305|\n",
            "|     j|  3354|\n",
            "|     k|  9491|\n",
            "|     l| 29697|\n",
            "|     m| 55800|\n",
            "|     n| 26834|\n",
            "|     o| 43590|\n",
            "|     p| 27860|\n",
            "|     q|  2378|\n",
            "|     r| 14396|\n",
            "|     s| 66069|\n",
            "|     t|126395|\n",
            "+------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.types import NullType\n",
        "dfLetterCounts = sqlContext.createDataFrame(countKeys)\\\n",
        ".withColumnRenamed('_1', 'Letter')\\\n",
        ".withColumnRenamed('_2', 'Count')\n",
        "dfLetterCounts = dfLetterCounts.filter(dfLetterCounts.Letter != 'null')\n",
        "dfLetterCounts.sort(dfLetterCounts.Letter).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output CSV"
      ],
      "metadata": {
        "id": "5Sy5iIsTam4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfLetterCounts.toPandas().to_csv('LetterCounts.csv', index=False)\n"
      ],
      "metadata": {
        "id": "vJycpCXE7YcK"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Dead Code"
      ],
      "metadata": {
        "id": "9YyqSzHjS49B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"Attempt 2\n",
        "Words = input_file.flatMap(\n",
        "    lambda line: line.split())\n",
        "Words = Words.map(lambda letter : letter, Words)\n",
        "Letters = Words.map(lambda letter : letter[x], lambda x : x, Words[x])\n",
        "LetterCount = Letters.map(lambda letter : (letter , 1))\n",
        "countKeys = LetterCount.reduceByKey(lambda a, b : a + b)\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"Attempt 1\n",
        "Words = input_file.flatMap(\n",
        "    lambda line: line.split())\n",
        "    #re.findall(r\"[a-zA-Z]\",line.split()))\n",
        "Letters = Words.map(lambda word :\n",
        "                      re.findall(r\"[a-zA-Z]\", word))\n",
        "Letters = LetterObj.map(lambda letter : \n",
        "                        letter.match)\n",
        "LetterCount = Words.map(lambda letter: (letter, 1))\n",
        "countKeys = LetterCount.reduceByKey(lambda a, b: a + b)\n",
        "FiveWordPhrase = Words.map(lambda phrase : (phrase[0] + phrase[1] + phrase[2] + phrase[3] + phrase[4]) if len(phrase) >=5 else phrase)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "SgISJwT14fa7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}